{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intraclass correlation statistics to test item performance models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two ways of correlation estimates:\n",
    "\n",
    "- Analysis of Variance (ANOVA)\n",
    "- Permutation Resambling - based on Monte Carlo Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA vs Permutation Resambling (advantages and disadvantages):\n",
    "\n",
    "ANOVA:\n",
    "- fast\n",
    "- accurate\n",
    "- provides reliable confidence limits for the ICC\n",
    "- assumes the underlying ariables are approximately Gaussian\n",
    "- less sensitive to missing data than Permutation Resambling\n",
    "\n",
    "Permutation Resambling:\n",
    "- distribution free\n",
    "- highly flexible\n",
    "- requires much more computational effort than ANOVA\n",
    "- more sensitive to missing data than ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard analysis of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three variation sources:\n",
    "- **the between rows item effect**: \n",
    "\n",
    "$MSi$ - mean square\n",
    "\n",
    "$dfi = m - 1$ - degrees of freedom\n",
    "\n",
    "$E(MSi) = n\\sigma_{\\beta}^{2} + \\sigma_{\\epsilon}$ - expected value\n",
    "\n",
    "- **the between-column participant effect**:\n",
    "\n",
    "$MSp$ - mean square\n",
    "\n",
    "$dfp = n - 1$ - degrees of freedom\n",
    "\n",
    "$E(MSe) = m\\sigma_{\\alpha}^{2} + \\sigma_{\\epsilon}$ - expected value\n",
    "\n",
    "- **the residual error effect**:\n",
    "\n",
    "$MSe$ - mean square\n",
    "\n",
    "$dfp = (n - 1)(m - 1) = N - 1 - dfi - dfp$ - degrees of freedom\n",
    "\n",
    "where:\n",
    "\n",
    "N - total number of available measures in the matrix\n",
    "\n",
    "$E(MSe) = \\sigma_{\\epsilon}$ - expected value\n",
    "\n",
    "**Estimate of the q-ratio**:\n",
    "$$ \\hat{q}  = \\frac{MSi - MSe}{nMSe}$$\n",
    "\n",
    "**Estimate of the interclass coefficient**:\n",
    "$$\\frac{n\\hat{q}}{n\\hat{q} + 1} = \\frac{MSi - MSe}{MSi}$$\n",
    "\n",
    "**The confidence interval of probability $1 - \\alpha$**:\n",
    "$$\\Bigg[1 - \\frac{F_{1 - \\alpha/2}(dfi, dfe)}{F_{obs}}; 1 - \\frac{1}{F_{obs} x F_{1 - \\alpha/2}(dfe, dfi)}\\Bigg]$$\n",
    "\n",
    "where:\n",
    "\n",
    "$F_{obs}= MSi/MSe$\n",
    "\n",
    "$F_{p}(a, b)$ - quantile of probability of p of Fisher $F$ distribution with $a$ (numerator) and $b$ (donominator) degrees of freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interclass correlation coefficient interpretatin \n",
    "[Source: https://en.wikipedia.org/wiki/Intraclass_correlation]:\n",
    "\n",
    "Guidelines for interpretation proposed by Cicchetti (1994):\n",
    "- less than 0.40—poor\n",
    "- between 0.40 and 0.59—fair\n",
    "- between 0.60 and 0.74—good\n",
    "- between 0.75 and 1.00—excellent\n",
    "\n",
    "Guidelines for interpretation proposed by Koo and Li (2016):\n",
    "- below 0.50: poor\n",
    "- between 0.50 and 0.75: moderate\n",
    "- between 0.75 and 0.90: good\n",
    "- above 0.90: excellent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all requaired packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats # for calculate interval for ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all datasets\n",
    "\n",
    "# Respond Time 1 database\n",
    "RT1 = pd.read_csv('/Users/klaudiaszczygiel/data_science/Applied_statistics/ERPbox/RTdataB1.csv', header=None)\n",
    "RT_1 = RT1.copy() # for easier computation later\n",
    "\n",
    "# Respond Time 2 database\n",
    "RT2 = pd.read_csv('/Users/klaudiaszczygiel/data_science/Applied_statistics/ERPbox/RTdataB2.csv', header=None)\n",
    "RT_2 = RT2.copy() \n",
    "\n",
    "# Respond Time 3 database\n",
    "RT3 = pd.read_csv('/Users/klaudiaszczygiel/data_science/Applied_statistics/ERPbox/RTdataB3.csv', header=None)\n",
    "RT_3 = RT3.copy() \n",
    "\n",
    "# Respond Time 4 database\n",
    "RT4 = pd.read_csv('/Users/klaudiaszczygiel/data_science/Applied_statistics/ERPbox/RTdataB4.csv', header=None)\n",
    "RT_4 = RT4.copy() \n",
    "\n",
    "# naming2013 database\n",
    "df2013 = pd.read_csv('/Users/klaudiaszczygiel/data_science/Applied_statistics/ERPbox/naming2013.csv', header=None)\n",
    "df_2013 = df2013.copy() # for easier computation later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Respond Time 1 database (RT1)\n",
    "\n",
    "- detailed case, described step by step compution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>516.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>453</td>\n",
       "      <td>449</td>\n",
       "      <td>431</td>\n",
       "      <td>448</td>\n",
       "      <td>434.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>527</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>519.0</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>541</td>\n",
       "      <td>420.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>354</td>\n",
       "      <td>467</td>\n",
       "      <td>607</td>\n",
       "      <td>428</td>\n",
       "      <td>493.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>509.0</td>\n",
       "      <td>405</td>\n",
       "      <td>...</td>\n",
       "      <td>530.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>346</td>\n",
       "      <td>440.0</td>\n",
       "      <td>473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>421</td>\n",
       "      <td>412</td>\n",
       "      <td>440</td>\n",
       "      <td>344</td>\n",
       "      <td>397.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>395</td>\n",
       "      <td>...</td>\n",
       "      <td>483.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>422</td>\n",
       "      <td>416.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>425.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>429</td>\n",
       "      <td>480</td>\n",
       "      <td>447</td>\n",
       "      <td>482</td>\n",
       "      <td>439.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>375</td>\n",
       "      <td>...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>468</td>\n",
       "      <td>585.0</td>\n",
       "      <td>621</td>\n",
       "      <td>379.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>511</td>\n",
       "      <td>555</td>\n",
       "      <td>517</td>\n",
       "      <td>458</td>\n",
       "      <td>470.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>452</td>\n",
       "      <td>...</td>\n",
       "      <td>622.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>468</td>\n",
       "      <td>553.0</td>\n",
       "      <td>516</td>\n",
       "      <td>495.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>490.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1    2    3    4    5      6      7      8    9    ...    190  \\\n",
       "0  516.0  430.0  453  449  431  448  434.0  411.0  473.0  527  ...    NaN   \n",
       "1  278.0    NaN  354  467  607  428  493.0    NaN  509.0  405  ...  530.0   \n",
       "2  419.0  379.0  421  412  440  344  397.0  435.0  429.0  395  ...  483.0   \n",
       "3  425.0  406.0  429  480  447  482  439.0  461.0  417.0  375  ...  600.0   \n",
       "4  460.0  373.0  511  555  517  458  470.0  479.0  583.0  452  ...  622.0   \n",
       "\n",
       "     191  192    193  194    195    196    197    198    199  \n",
       "0  519.0  597    NaN  541  420.0  479.0  523.0  474.0  456.0  \n",
       "1  411.0  346  440.0  473    NaN  415.0  480.0  411.0  432.0  \n",
       "2  392.0  415    NaN  422  416.0  437.0  410.0  502.0  404.0  \n",
       "3  597.0  468  585.0  621  379.0  449.0  661.0  548.0  586.0  \n",
       "4  457.0  468  553.0  516  495.0  572.0  547.0  648.0  490.0  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick overview\n",
    "\n",
    "RT1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of lists from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning to improve and simplyfy the calculations we convert dataframe into matrix (direct matrices in python are not avaible but we can skip this problem by building list of lists from our datasets which works similar to the matrices). Next we transpose our matrices because we want to have `m` rows (nb of items) and `n` columns (nb of participants).\n",
    "\n",
    "**Desired input**:\n",
    "\n",
    "`m` : nb of items in the items populations\n",
    "\n",
    "`n` : nb of participants in the participants population\n",
    "\n",
    "`m x n` : matrix of behavioural measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT1 = np.array(RT1.values.tolist()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[516., 278., 419., ...,  nan, 275., 541.],\n",
       "       [430.,  nan, 379., ..., 276., 415., 605.],\n",
       "       [453., 354., 421., ..., 287., 564., 624.],\n",
       "       ...,\n",
       "       [523., 480., 410., ..., 469., 582., 479.],\n",
       "       [474., 411., 502., ..., 459., 350., 552.],\n",
       "       [456., 432., 404., ..., 482., 518., 502.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick overview - seems to look properly, now row are responsible for the items and the columns for participants\n",
    "RT1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single functions required for computing ICC\n",
    "\n",
    "- to better understanding how to caompute components for ANOVA\n",
    "- functions writes for RT1 databeses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 200\n",
    "n = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_j: sum the total respond time for each participants (function for double loop)\n",
    "t_j = []\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        t_j.append(np.nansum(RT1.transpose()[:][j]))\n",
    "#t_j[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_j: sum the total respond time for each participants (sigle function)\n",
    "\n",
    "def participant_time_sum():\n",
    "    '''Return list which contain sum of respond time for each participant (sums value for each column)'''\n",
    "    t_j = []\n",
    "    for j in range(n):\n",
    "        t_j.append(np.nansum(RT1.transpose()[:][j]))\n",
    "    return t_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_i: sums all of items value in rows\n",
    "\n",
    "def item_sum():\n",
    "    '''Return list which contain sum of respond time for each item (sums value for each row).'''\n",
    "    t_i = []\n",
    "    for i in range(m):\n",
    "        t_i.append(np.nansum(RT1[i][:]))\n",
    "    return t_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mitem:  return list of means for each item, work well: nanmean - just skip NaN without removing rows\n",
    "\n",
    "def mean_of_item():\n",
    "    '''Return list of means for each item (calculate mean for each row).\n",
    "       Deal also with missing values'''\n",
    "    mitem = []\n",
    "    for i in range(m):\n",
    "        mitem.append(np.nanmean(RT1[i][:]))\n",
    "    return mitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of squares\n",
    "\n",
    "def sum_of_squares():\n",
    "    '''Return sum of squres for all values of \n",
    "       respond time. Deal also with missing values.'''\n",
    "    sx2 = 0\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            sx2 = sx2 + np.nansum(RT1[i][j]**2)\n",
    "    return sx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All functions blend together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved version\n",
    "\n",
    "m = 200 # nb of words\n",
    "n = 48 # nb of participants\n",
    "\n",
    "sx2 = 0 # sum of squares\n",
    "t_i = []\n",
    "t_j = []\n",
    "mitem = [] # list for means fro each item\n",
    "for i in range(m):\n",
    "    mitem.append(np.nanmean(RT1[i][:]))\n",
    "    t_i.append(np.nansum(RT1[i][:]))\n",
    "    for j in range(n):\n",
    "        if RT1[i][j] != 'nan':\n",
    "            t_j.append(np.nansum(RT1.transpose()[:][j])) # work as expected\n",
    "            sx2 = sx2 + np.nansum(RT1[i][j]**2) # work as expected - checked with another method of computing\n",
    "\n",
    "n_i = list(RT_1.apply(lambda x: x.count(), axis=0)) # totall non missing values for rows\n",
    "n_j = list(RT_1.apply(lambda x: x.count(), axis=1)) # totall non missing values for columns        \n",
    "N = np.sum(n_i)\n",
    "t = np.sum(t_i)\n",
    "ss = sx2 - t**2/N \n",
    "ssi = np.sum([x**2/y for x, y in zip(map(float, t_i), map(float, n_i))]) - t**2/N # each of elements from t_i raised to power 2 and divided by 48 and sums\n",
    "ssj = np.sum([x**2/y for x, y in zip(map(float, t_j[:n]), map(float, n_j))]) - t**2/N # like higher\n",
    "ssij = ss - ssi - ssj\n",
    "dfi = m-1\n",
    "dfj = n-1\n",
    "dfij = N-1-dfi-dfj\n",
    "msi = ssi/dfi\n",
    "vij = ssij/dfij\n",
    "vi = max(0, (msi - vij)/n)\n",
    "qAV = vi/vij\n",
    "icc = vi/(vi+vij/n)\n",
    "F_obs = msi/vij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 9166\n",
      "t: 4550829.0\n",
      "ss: 75469714.61629915\n",
      "ssi: 5280052.288134098\n",
      "ssj: 28167883.783376217\n",
      "ssij: 42021778.54478884\n",
      "dfi: 199\n",
      "dfj: 47\n",
      "dfij: 8919\n",
      "msi: 26532.926071025617\n",
      "vij: 4711.489914204377\n",
      "vi: 454.6132532671092\n",
      "qAV: 0.09649033777967433\n",
      "icc: 0.82242855908194\n",
      "F_obs: 5.631536213424368\n"
     ]
    }
   ],
   "source": [
    "print(\"N:\",N) # checked - ok\n",
    "print(\"t:\",t) # checked - ok\n",
    "print(\"ss:\",ss) # compute properly, checked with another method\n",
    "print(\"ssi:\",ssi) # compute properly, checked with another method\n",
    "print(\"ssj:\",ssj) # compute properly, checked with another method\n",
    "print(\"ssij:\",ssij) # compute properly, checked with another method\n",
    "print(\"dfi:\",dfi) # checked - ok\n",
    "print(\"dfj:\",dfj) # checked - ok\n",
    "print(\"dfij:\",dfij) # checked - ok\n",
    "print(\"msi:\",msi) # compute properly, checked with another method\n",
    "print(\"vij:\",vij) #check\n",
    "print(\"vi:\",vi) #chceck\n",
    "print(\"qAV:\",qAV) \n",
    "print(\"icc:\",icc) # seems to work properly\n",
    "print(\"F_obs:\",F_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the ICC confidence intervals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantiles for alpha=0.95: 1.208720821014422,1.2321271218589724\n",
      "Quantiles for alpha=0.99: 1.2811384278966609,1.3180068682994863\n",
      "Quantiles for alpha=0.999: 1.3687652129202201,1.427749119290794\n"
     ]
    }
   ],
   "source": [
    "pconf = [0.95, 0.99, 0.999]\n",
    "\n",
    "Q1f = []\n",
    "Q2f = []\n",
    "for i in range(len(pconf)):\n",
    "    Q1 = stats.f.ppf(1 - (1 - pconf[i])/2, dfi, dfij)\n",
    "    Q2  = stats.f.ppf(1 - (1 - pconf[i])/2, dfij, dfi)\n",
    "    Q1f.append(Q1)\n",
    "    Q2f.append(Q2)\n",
    "    print(f'Quantiles for alpha={pconf[i]}: {Q1},{Q2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf():\n",
    "    ''''Return confidence intervals for Fisher F-distribution'''\n",
    "    conf = np.zeros((3,3))\n",
    "    for i in range(len(pconf)):\n",
    "        conf[i][0] = pconf[i]\n",
    "        conf[i][1] = 1 - (Q1f[i]/F_obs)\n",
    "        conf[i][2] = 1 - 1/(Q2f[i] * F_obs)\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95      , 0.7853657 , 0.85588221],\n",
       "       [0.99      , 0.7725064 , 0.86527275],\n",
       "       [0.999     , 0.75694639, 0.8756284 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. General case for RT1, RT2, RT3, RT4, naming2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICC(m,n,data,data_1):\n",
    "    '''Function which return ICC values with confidence interval for sigle database.'''\n",
    "    sx2 = 0 # sum of squares\n",
    "    t_i = []\n",
    "    t_j = []\n",
    "    mitem = [] # list for means fro each item\n",
    "    for i in range(m):\n",
    "        mitem.append(np.nanmean(data[i][:]))\n",
    "        t_i.append(np.nansum(data[i][:]))\n",
    "        for j in range(n):\n",
    "            if data[i][j] != 'nan':\n",
    "                t_j.append(np.nansum(data.transpose()[:][j])) # work as expected\n",
    "                sx2 = sx2 + np.nansum(data[i][j]**2) # work as expected - checked with another method of computing\n",
    "\n",
    "    n_i = list(data_1.apply(lambda x: x.count(), axis=0)) # totall non missing values for rows\n",
    "    n_j = list(data_1.apply(lambda x: x.count(), axis=1)) # totall non missing values for columns        \n",
    "    N = np.sum(n_i)\n",
    "    t = np.sum(t_i)\n",
    "    ss = sx2 - t**2/N \n",
    "    ssi = np.sum([x**2/y for x, y in zip(map(float, t_i), map(float, n_i))]) - t**2/N # each of elements from t_i raised to power 2 and divided by 48 and sums\n",
    "    ssj = np.sum([x**2/y for x, y in zip(map(float, t_j[:n]), map(float, n_j))]) - t**2/N # like higher\n",
    "    ssij = ss - ssi - ssj\n",
    "    dfi = m-1\n",
    "    dfj = n-1\n",
    "    dfij = N-1-dfi-dfj\n",
    "    msi = ssi/dfi\n",
    "    vij = ssij/dfij\n",
    "    vi = max(0, (msi - vij)/n)\n",
    "    qAV = vi/vij\n",
    "    icc = vi/(vi+vij/n)\n",
    "    F_obs = msi/vij\n",
    "    \n",
    "    def conf():\n",
    "        ''''Return confidence intervals for Fisher F-distribution'''\n",
    "        pconf = [0.95, 0.99, 0.999]\n",
    "        Q1f = []\n",
    "        Q2f = []\n",
    "        for i in range(len(pconf)):\n",
    "            Q1 = stats.f.ppf(1 - (1 - pconf[i])/2, dfi, dfij)\n",
    "            Q2  = stats.f.ppf(1 - (1 - pconf[i])/2, dfij, dfi)\n",
    "            Q1f.append(Q1)\n",
    "            Q2f.append(Q2)\n",
    "    \n",
    "        conf = np.zeros((3,3))\n",
    "        for i in range(len(pconf)):\n",
    "            conf[i][0] = pconf[i]\n",
    "            conf[i][1] = 1 - (Q1f[i]/F_obs)\n",
    "            conf[i][2] = 1 - 1/(Q2f[i] * F_obs)\n",
    "        return conf\n",
    "    \n",
    "    return print(f'ICC value: {icc}'), print(f'Confidence intervals: \\n{conf()}'), print('*'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC value: 0.82242855908194\n",
      "Confidence intervals: \n",
      "[[0.95       0.7853657  0.85588221]\n",
      " [0.99       0.7725064  0.86527275]\n",
      " [0.999      0.75694639 0.8756284 ]]\n",
      "****************************************\n",
      "ICC value: 0.7536994056041846\n",
      "Confidence intervals: \n",
      "[[0.95       0.70228492 0.80010484]\n",
      " [0.99       0.68444578 0.81313075]\n",
      " [0.999      0.66285973 0.82749523]]\n",
      "****************************************\n",
      "ICC value: 0.784645450992303\n",
      "Confidence intervals: \n",
      "[[0.95       0.73968578 0.82522313]\n",
      " [0.99       0.72408594 0.83661301]\n",
      " [0.999      0.70520925 0.84917322]]\n",
      "****************************************\n",
      "ICC value: 0.750283187069434\n",
      "Confidence intervals: \n",
      "[[0.95       0.69815607 0.797332  ]\n",
      " [0.99       0.6800697  0.81053852]\n",
      " [0.999      0.65818452 0.82510219]]\n",
      "****************************************\n",
      "ICC value: 0.8971072920273282\n",
      "Confidence intervals: \n",
      "[[0.95       0.87577881 0.91641084]\n",
      " [0.99       0.86838793 0.9218349 ]\n",
      " [0.999      0.85945248 0.92782002]]\n",
      "****************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICC(200, 48, RT1, RT_1)\n",
    "ICC(200, 48, RT2, RT_2)\n",
    "ICC(200, 48, RT3, RT_3)\n",
    "ICC(200, 48, RT4, RT_4)\n",
    "ICC(200, 100, df2013, df_2013)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
